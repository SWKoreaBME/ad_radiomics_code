{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Composition\n",
    "\n",
    "1. Texture feature 851 * 2\n",
    "2. Deep feature 128 * 2\n",
    "3. clinical feature 3\n",
    "\n",
    "1. version\n",
    "    1. version 1 : Texture Only\n",
    "    2. version 2 : Deep Only\n",
    "    3. version 3 : Texture + clinical\n",
    "    4. version 4 : Deep + clinical\n",
    "    5. version 5 : Texture + Deep + clinical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import os\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "\n",
    "import seaborn as sns\n",
    "from sklearn.feature_selection import mutual_info_classif, SelectKBest\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, roc_auc_score, multilabel_confusion_matrix\n",
    "\n",
    "from collections import Counter\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from feature_classifier_utils import ensemble_voting, GridSVM, Lasso_feature_selection\n",
    "from feature_oversampling_utils import random_oversampling\n",
    "from feature_performance_utils import load_texture_feature,\\\n",
    "                                        load_clinical_data,\\\n",
    "                                        save_confusion_matrix,\\\n",
    "                                        Validation, \\\n",
    "                                        normal_porosis,\\\n",
    "                                        save_roc_curve, \\\n",
    "                                        dummy_labelize_swk, \\\n",
    "                                        binarize_threshold_swk\n",
    "\n",
    "from random import shuffle\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from tqdm import notebook\n",
    "\n",
    "def ad_dlr_dataloader():\n",
    "    texture_features = ['../Data/ad_radiomics/texture_feature/left_mask.csv', '../Data/ad_radiomics/texture_feature/right_mask.csv']\n",
    "    rename_file = lambda x : x.rename(columns={\"Unnamed: 0\" : \"file\"})\n",
    "\n",
    "    left_texture = rename_file(pd.read_csv(texture_features[0]))\n",
    "    right_texture = rename_file(pd.read_csv(texture_features[1]))\n",
    "\n",
    "    deep_features = glob(os.path.join('../Data/ad_radiomics/deep_feature/', '*.npy'))\n",
    "    label_file = '../Data/ad_radiomics/label_dict.pickle'\n",
    "    clinical_file = '../Data/ad_radiomics/clinical_data.pickle'\n",
    "\n",
    "    with open(label_file, 'rb') as file: label_dict = pickle.load(file)\n",
    "    with open(clinical_file, 'rb') as file: clinical_dict = pickle.load(file)\n",
    "\n",
    "    feature_names = np.array(list(pd.read_csv(texture_features[0]).columns)[1:])\n",
    "\n",
    "    whole_feature = []\n",
    "    whole_label = []\n",
    "    whole_subjects = []\n",
    "\n",
    "    for key, clinical_value in notebook.tqdm_notebook(clinical_dict.items()):\n",
    "\n",
    "        left_texture_feature = list(left_texture.loc[left_texture['file'] == key+'_L'].values[0, 1:])\n",
    "        right_texture_feature = list(right_texture.loc[right_texture['file'] == key+'_R'].values[0, 1:])\n",
    "\n",
    "        left_deep_feature = list([np.load(x) for x in deep_features if key+'_0' in x][0])\n",
    "        right_deep_feature = list([np.load(x) for x in deep_features if key+'_1' in x][0])\n",
    "\n",
    "        clinical_feature = clinical_value\n",
    "        label = label_dict[key]\n",
    "        \n",
    "        label = 0 if label in [0, 1] else 1\n",
    "\n",
    "        whole_feature.append([*left_texture_feature,\n",
    "                              *right_texture_feature,\n",
    "                              *left_deep_feature,\n",
    "                              *right_deep_feature,\n",
    "                              *clinical_feature])\n",
    "\n",
    "        whole_label.append(label)\n",
    "        whole_subjects.append(key)\n",
    "\n",
    "    whole_feature = np.array(whole_feature)\n",
    "    whole_label = np.array(whole_label)\n",
    "\n",
    "    return whole_feature, whole_label, whole_subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def result2csv(results, filename = './result.csv'):\n",
    "    means = []\n",
    "    stds = []\n",
    "    for key, value in results.items():\n",
    "        means.extend(np.mean(value, axis=0))\n",
    "        stds.extend(np.std(value, axis=0))\n",
    "\n",
    "    columns = ['accuracy', 'auroc', 'precision', 'f1']\n",
    "    keys = list(results.keys())\n",
    "    index = []\n",
    "    for key in keys:\n",
    "        for col in columns:\n",
    "            index.append((key, col))\n",
    "\n",
    "    index = pd.MultiIndex.from_tuples(index, names=['type', 'metric'])\n",
    "    pd.DataFrame(np.array([means, stds]).T, index=index, columns=['mean', 'std']).to_csv(filename)\n",
    "    \n",
    "reporting_results = dict(\n",
    "    v1=[],\n",
    "    v2=[],\n",
    "    v3=[],\n",
    "    v4=[],\n",
    "    v5=[]\n",
    ")\n",
    "    \n",
    "def DLR(version, TR=0.04, RANDOM_NUMBER=42, data=None, test_split=False):\n",
    "    \n",
    "    if version == 'v1':\n",
    "        CLINIC, DEEP, TEXTURE = False, False, True\n",
    "    elif version == 'v2':\n",
    "        CLINIC, DEEP, TEXTURE = False, True, False\n",
    "    elif version == 'v3':\n",
    "        CLINIC, DEEP, TEXTURE = True, False, True\n",
    "    elif version == 'v4':\n",
    "        CLINIC, DEEP, TEXTURE = True, True, False\n",
    "    elif version == 'v5':\n",
    "        CLINIC, DEEP, TEXTURE = True, True, True\n",
    "    \n",
    "    # Data Loading\n",
    "    if data is None:\n",
    "        try:\n",
    "            X = np.load(os.path.join(save_folder, '{}_X.npy'.format(version)))\n",
    "            Y = np.load(os.path.join(save_folder, '{}_Y.npy'.format(version)))\n",
    "        except:\n",
    "            raise ValueError(\"input should be specified\")\n",
    "            return\n",
    "    else:\n",
    "        X, Y = data\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                        Y,\n",
    "                                                        test_size=0.30,\n",
    "                                                        random_state=RANDOM_NUMBER)\n",
    "    # Standard Scaler\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    print(\"num features before LASSO : \", X_train.shape[1])\n",
    "\n",
    "    \"\"\"\n",
    "        Feature Selection\n",
    "    \"\"\"\n",
    "\n",
    "    # only Texture | version 1\n",
    "    if ( not CLINIC ) & TEXTURE & ( not DEEP ):\n",
    "        sfm = Lasso_feature_selection(X_train, y_train, tr=TR)\n",
    "        X_train = sfm.transform(X_train)\n",
    "        X_test = sfm.transform(X_test)\n",
    "\n",
    "    # only Deep | version 2\n",
    "    elif ( not CLINIC ) & ( not TEXTURE ) & DEEP :\n",
    "        sfm = Lasso_feature_selection(X_train, y_train, tr=TR)\n",
    "        X_train = sfm.transform(X_train)\n",
    "        X_test = sfm.transform(X_test)\n",
    "\n",
    "    # Texture + clinic | version 3\n",
    "    elif CLINIC & TEXTURE & ( not DEEP ) :\n",
    "        sfm = Lasso_feature_selection(X_train[:, :-3], y_train, tr=TR)\n",
    "        X_train = np.hstack([sfm.transform(X_train[:, :-3]), X_train[:, -3:]])\n",
    "        X_test = np.hstack([sfm.transform(X_test[:, :-3]), X_test[:, -3:]])\n",
    "\n",
    "    # deep + clinic | version 4\n",
    "    elif CLINIC & ( not TEXTURE ) & DEEP :\n",
    "        sfm = Lasso_feature_selection(X_train[:, :-3], y_train, tr=TR)\n",
    "        X_train = np.hstack([sfm.transform(X_train[:, :-3]), X_train[:, -3:]])\n",
    "        X_test = np.hstack([sfm.transform(X_test[:, :-3]), X_test[:, -3:]])\n",
    "\n",
    "    # texture + deep + clinic | version 5\n",
    "    elif CLINIC & TEXTURE & DEEP :\n",
    "        # texture + clinic + deep\n",
    "        clinical_features = X_train[:, -3:]\n",
    "        deep_features = X_train[:, -259:-3]\n",
    "        texture_features = X_train[:, :-259]\n",
    "\n",
    "        deep_sfm = Lasso_feature_selection(deep_features, y_train, tr=0.06)\n",
    "        texture_sfm = Lasso_feature_selection(texture_features, y_train, tr=0.04)\n",
    "\n",
    "        X_train = np.hstack([texture_sfm.transform(texture_features),\n",
    "                             deep_sfm.transform(deep_features),\n",
    "                             clinical_features])\n",
    "\n",
    "        clinical_features_test = X_test[:, -3:]\n",
    "        deep_features_test = X_test[:, -259:-3]\n",
    "        texture_features_test = X_test[:, :-259]\n",
    "\n",
    "        X_test = np.hstack([texture_sfm.transform(texture_features_test),\n",
    "                 deep_sfm.transform(deep_features_test),\n",
    "                 clinical_features_test])\n",
    "\n",
    "        sfm = [texture_sfm, deep_sfm]\n",
    "\n",
    "    print(\"num features after LASSO : \", X_train.shape[1])\n",
    "\n",
    "    # LASSO feature Selection -> Random OverSampling\n",
    "    \"\"\"\n",
    "        Threshold > 0.1, 0.15, 0.2\n",
    "    \"\"\"\n",
    "    X_train, y_train = random_oversampling(X_train, y_train, random_state=RANDOM_NUMBER)\n",
    "\n",
    "    # model\n",
    "    classifier = ensemble_voting(X_train, y_train, random_state=RANDOM_NUMBER, cv=5)\n",
    "\n",
    "    # Training\n",
    "    classifier.fit(X_train, y_train)\n",
    "\n",
    "    # Testing\n",
    "    test_result = Validation(classifier, X_test, y_test)\n",
    "\n",
    "    # Save Result\n",
    "    reporting_results[version].append(list(test_result[:4]))\n",
    "\n",
    "    output = dict(\n",
    "        model = classifier,\n",
    "        version = version,\n",
    "        scaler = scaler,\n",
    "        sfm = sfm,\n",
    "        random_number = RANDOM_NUMBER\n",
    "    )\n",
    "    return output\n",
    "    \n",
    "def sfm_transform(sfm, data):\n",
    "    return data[:, sfm.get_support() == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data Loaded\n",
      "\n",
      " 0.01\n",
      "num features before LASSO :  1702\n",
      "num features after LASSO :  4\n",
      "Ensemble Voting Grid search running...\n",
      "Random Forest Grid search running...\n",
      "{'class_weight': None, 'criterion': 'gini', 'max_depth': 8, 'max_features': 'auto', 'n_estimators': 200}\n",
      "XGBoost Grid search running...\n",
      "{'booster': 'gbtree', 'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 500}\n",
      "Adaboost Grid search running...\n",
      "{'learning_rate': 1.0, 'n_estimators': 200}\n",
      "Estimators Ready\n",
      "Voting Classifier Grid search running ... \n",
      "{'voting': 'soft'}\n",
      "done\n",
      "================================\n",
      "Validation\n",
      "confusion :  [[24  1]\n",
      " [11  5]]\n",
      "Accuracy : 0.707\n",
      "roc-auc score : 0.802\n",
      "f1 score : 0.455\n",
      "precision : 0.833\n",
      "\n",
      " 0.02\n",
      "num features before LASSO :  1702\n",
      "num features after LASSO :  4\n",
      "Ensemble Voting Grid search running...\n",
      "Random Forest Grid search running...\n",
      "{'class_weight': None, 'criterion': 'gini', 'max_depth': 8, 'max_features': 'auto', 'n_estimators': 200}\n",
      "XGBoost Grid search running...\n",
      "{'booster': 'gbtree', 'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 500}\n",
      "Adaboost Grid search running...\n",
      "{'learning_rate': 1.0, 'n_estimators': 200}\n",
      "Estimators Ready\n",
      "Voting Classifier Grid search running ... \n",
      "{'voting': 'soft'}\n",
      "done\n",
      "================================\n",
      "Validation\n",
      "confusion :  [[24  1]\n",
      " [11  5]]\n",
      "Accuracy : 0.707\n",
      "roc-auc score : 0.802\n",
      "f1 score : 0.455\n",
      "precision : 0.833\n",
      "\n",
      " 0.01\n",
      "num features before LASSO :  256\n",
      "num features after LASSO :  16\n",
      "Ensemble Voting Grid search running...\n",
      "Random Forest Grid search running...\n",
      "{'class_weight': None, 'criterion': 'gini', 'max_depth': 8, 'max_features': 'auto', 'n_estimators': 200}\n",
      "XGBoost Grid search running...\n",
      "{'booster': 'gbtree', 'learning_rate': 0.01, 'max_depth': 7, 'n_estimators': 500}\n",
      "Adaboost Grid search running...\n",
      "{'learning_rate': 1.0, 'n_estimators': 50}\n",
      "Estimators Ready\n",
      "Voting Classifier Grid search running ... \n",
      "{'voting': 'soft'}\n",
      "done\n",
      "================================\n",
      "Validation\n",
      "confusion :  [[25  0]\n",
      " [ 3 13]]\n",
      "Accuracy : 0.927\n",
      "roc-auc score : 0.990\n",
      "f1 score : 0.897\n",
      "precision : 1.000\n",
      "\n",
      " 0.02\n",
      "num features before LASSO :  256\n",
      "num features after LASSO :  10\n",
      "Ensemble Voting Grid search running...\n",
      "Random Forest Grid search running...\n",
      "{'class_weight': None, 'criterion': 'gini', 'max_depth': 8, 'max_features': 'auto', 'n_estimators': 200}\n",
      "XGBoost Grid search running...\n",
      "{'booster': 'gbtree', 'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 200}\n",
      "Adaboost Grid search running...\n",
      "{'learning_rate': 1.0, 'n_estimators': 50}\n",
      "Estimators Ready\n",
      "Voting Classifier Grid search running ... \n",
      "{'voting': 'soft'}\n",
      "done\n",
      "================================\n",
      "Validation\n",
      "confusion :  [[25  0]\n",
      " [ 5 11]]\n",
      "Accuracy : 0.878\n",
      "roc-auc score : 0.993\n",
      "f1 score : 0.815\n",
      "precision : 1.000\n",
      "\n",
      " 0.01\n",
      "num features before LASSO :  1705\n",
      "num features after LASSO :  7\n",
      "Ensemble Voting Grid search running...\n",
      "Random Forest Grid search running...\n",
      "{'class_weight': None, 'criterion': 'gini', 'max_depth': 8, 'max_features': 'auto', 'n_estimators': 200}\n",
      "XGBoost Grid search running...\n",
      "{'booster': 'gbtree', 'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 500}\n",
      "Adaboost Grid search running...\n",
      "{'learning_rate': 1.0, 'n_estimators': 50}\n",
      "Estimators Ready\n",
      "Voting Classifier Grid search running ... \n",
      "{'voting': 'soft'}\n",
      "done\n",
      "================================\n",
      "Validation\n",
      "confusion :  [[24  1]\n",
      " [12  4]]\n",
      "Accuracy : 0.683\n",
      "roc-auc score : 0.770\n",
      "f1 score : 0.381\n",
      "precision : 0.800\n",
      "\n",
      " 0.02\n",
      "num features before LASSO :  1705\n",
      "num features after LASSO :  7\n",
      "Ensemble Voting Grid search running...\n",
      "Random Forest Grid search running...\n",
      "{'class_weight': None, 'criterion': 'gini', 'max_depth': 8, 'max_features': 'auto', 'n_estimators': 200}\n",
      "XGBoost Grid search running...\n",
      "{'booster': 'gbtree', 'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 500}\n",
      "Adaboost Grid search running...\n",
      "{'learning_rate': 1.0, 'n_estimators': 50}\n",
      "Estimators Ready\n",
      "Voting Classifier Grid search running ... \n",
      "{'voting': 'soft'}\n",
      "done\n",
      "================================\n",
      "Validation\n",
      "confusion :  [[24  1]\n",
      " [12  4]]\n",
      "Accuracy : 0.683\n",
      "roc-auc score : 0.770\n",
      "f1 score : 0.381\n",
      "precision : 0.800\n",
      "\n",
      " 0.01\n",
      "num features before LASSO :  259\n",
      "num features after LASSO :  19\n",
      "Ensemble Voting Grid search running...\n",
      "Random Forest Grid search running...\n",
      "{'class_weight': None, 'criterion': 'gini', 'max_depth': 8, 'max_features': 'auto', 'n_estimators': 200}\n",
      "XGBoost Grid search running...\n",
      "{'booster': 'gbtree', 'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 200}\n",
      "Adaboost Grid search running...\n",
      "{'learning_rate': 1.0, 'n_estimators': 50}\n",
      "Estimators Ready\n",
      "Voting Classifier Grid search running ... \n",
      "{'voting': 'soft'}\n",
      "done\n",
      "================================\n",
      "Validation\n",
      "confusion :  [[25  0]\n",
      " [ 3 13]]\n",
      "Accuracy : 0.927\n",
      "roc-auc score : 0.995\n",
      "f1 score : 0.897\n",
      "precision : 1.000\n",
      "\n",
      " 0.02\n",
      "num features before LASSO :  259\n",
      "num features after LASSO :  13\n",
      "Ensemble Voting Grid search running...\n",
      "Random Forest Grid search running...\n",
      "{'class_weight': None, 'criterion': 'gini', 'max_depth': 8, 'max_features': 'auto', 'n_estimators': 200}\n",
      "XGBoost Grid search running...\n",
      "{'booster': 'gbtree', 'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 200}\n",
      "Adaboost Grid search running...\n",
      "{'learning_rate': 0.1, 'n_estimators': 100}\n",
      "Estimators Ready\n",
      "Voting Classifier Grid search running ... \n",
      "{'voting': 'soft'}\n",
      "done\n",
      "================================\n",
      "Validation\n",
      "confusion :  [[25  0]\n",
      " [ 5 11]]\n",
      "Accuracy : 0.878\n",
      "roc-auc score : 0.997\n",
      "f1 score : 0.815\n",
      "precision : 1.000\n",
      "\n",
      " 0.01\n",
      "num features before LASSO :  1961\n",
      "num features after LASSO :  8\n",
      "Ensemble Voting Grid search running...\n",
      "Random Forest Grid search running...\n",
      "{'class_weight': None, 'criterion': 'gini', 'max_depth': 8, 'max_features': 'auto', 'n_estimators': 400}\n",
      "XGBoost Grid search running...\n",
      "{'booster': 'gbtree', 'learning_rate': 0.01, 'max_depth': 7, 'n_estimators': 500}\n",
      "Adaboost Grid search running...\n",
      "{'learning_rate': 0.1, 'n_estimators': 200}\n",
      "Estimators Ready\n",
      "Voting Classifier Grid search running ... \n",
      "{'voting': 'soft'}\n",
      "done\n",
      "================================\n",
      "Validation\n",
      "confusion :  [[25  0]\n",
      " [13  3]]\n",
      "Accuracy : 0.683\n",
      "roc-auc score : 0.972\n",
      "f1 score : 0.316\n",
      "precision : 1.000\n",
      "\n",
      " 0.02\n",
      "num features before LASSO :  1961\n",
      "num features after LASSO :  8\n",
      "Ensemble Voting Grid search running...\n",
      "Random Forest Grid search running...\n",
      "{'class_weight': None, 'criterion': 'gini', 'max_depth': 8, 'max_features': 'auto', 'n_estimators': 400}\n",
      "XGBoost Grid search running...\n",
      "{'booster': 'gbtree', 'learning_rate': 0.01, 'max_depth': 7, 'n_estimators': 500}\n",
      "Adaboost Grid search running...\n",
      "{'learning_rate': 0.1, 'n_estimators': 200}\n",
      "Estimators Ready\n",
      "Voting Classifier Grid search running ... \n",
      "{'voting': 'soft'}\n",
      "done\n",
      "================================\n",
      "Validation\n",
      "confusion :  [[25  0]\n",
      " [13  3]]\n",
      "Accuracy : 0.683\n",
      "roc-auc score : 0.972\n",
      "f1 score : 0.316\n",
      "precision : 1.000\n"
     ]
    }
   ],
   "source": [
    "whole_feature, whole_label, whole_subjects = ad_dlr_dataloader()\n",
    "print(\"Data Loaded\")\n",
    "\n",
    "version_functions = dict(\n",
    "    v1 = lambda x : x[:, :851 * 2],\n",
    "    v2 = lambda x : x[:, -259:-3],\n",
    "    v3 = lambda x : np.concatenate([x[:, :851 * 2], x[:, -3:]], axis=1),\n",
    "    v4 = lambda x : x[:, -259:],\n",
    "    v5 = lambda x : x[:, :]\n",
    ")\n",
    "\n",
    "results = dict()\n",
    "for vers_index in range(1, 6):\n",
    "    version = 'v{}'.format(vers_index)\n",
    "    version_function = version_functions[version]\n",
    "    \n",
    "    data = [version_function(whole_feature), whole_label]\n",
    "    \n",
    "    for tr in [0.01, 0.02]:\n",
    "        print('\\n', tr)\n",
    "        train_module = DLR(version, TR=tr, RANDOM_NUMBER=42, data=data[:2], test_split=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  },
  "widgets": {
   "state": {
    "ec3734f1d8474183af51ffc333f2ed5a": {
     "views": [
      {
       "cell_index": 3
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
