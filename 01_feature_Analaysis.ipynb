{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "\n",
    "import seaborn as sns\n",
    "from sklearn.feature_selection import mutual_info_classif, SelectKBest\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from collections import Counter\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from feature_classifier_utils import ensemble_voting, GridSVM, Lasso_feature_selection\n",
    "from feature_performance_utils import load_texture_feature,\\\n",
    "                                        load_clinical_data,\\\n",
    "                                        save_confusion_matrix,\\\n",
    "                                        Validation, \\\n",
    "                                        normal_porosis,\\\n",
    "                                        save_roc_curve, \\\n",
    "                                        dummy_labelize_swk, \\\n",
    "                                        binarize_threshold_swk\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_prediction(feature_index, y_pred, y_pred_proba, y_test, filename, binary):\n",
    "    \n",
    "    if binary :\n",
    "\n",
    "        data = {\n",
    "            'true label' : y_test,\n",
    "            'pred label' : y_pred,\n",
    "            'confidence score for class 0' : y_pred_proba.T[0],\n",
    "            'confidence score for class 1' : y_pred_proba.T[1]\n",
    "        }\n",
    "        \n",
    "        pd.DataFrame(index=feature_index, data=data).to_excel(filename)\n",
    "        return \n",
    "    else:\n",
    "        \n",
    "        data = {\n",
    "            'true label' : y_test,\n",
    "            'pred label' : y_pred,\n",
    "            'confidence score for class 0' : y_pred_proba.T[0],\n",
    "            'confidence score for class 1' : y_pred_proba.T[1],\n",
    "            'confidence score for class 2' : y_pred_proba.T[2]\n",
    "        }\n",
    "        \n",
    "        pd.DataFrame(index=feature_index, data=data).to_excel(filename)\n",
    "        return\n",
    "\n",
    "def binary_class_configuration(feature_data, feature_label, delete_label):\n",
    "    \n",
    "    resampled_feature_data = []\n",
    "    resampled_feature_label = []\n",
    "    \n",
    "    for d, l in zip(feature_data, feature_label):\n",
    "        \n",
    "        if l == int(delete_label):\n",
    "            continue\n",
    "            \n",
    "        else:\n",
    "            resampled_feature_data.append(d)\n",
    "            resampled_feature_label.append(l)\n",
    "    \n",
    "    return resampled_feature_data, resampled_feature_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenate Clinical data to feature data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Whole feature : (270, 854)\n",
      "Whole labels : (270,)\n",
      "Whole subjects : 270\n",
      "Number by labels : Counter({1: 92, 2: 90, 0: 88})\n"
     ]
    }
   ],
   "source": [
    "texture_features = ['../result/left_mask.csv', '../result/right_mask.csv']\n",
    "label_file = '../data/label_dict.pickle'\n",
    "clinical_file = '../data/clinical_data.pickle'\n",
    "\n",
    "with open(label_file, 'rb') as file: label_dict = pickle.load(file)\n",
    "with open(clinical_file, 'rb') as file: clinical_dict = pickle.load(file)\n",
    "    \n",
    "feature_names = list(pd.read_csv(texture_features[0]).columns)[1:]\n",
    "\n",
    "whole_feature = []\n",
    "whole_label = []\n",
    "whole_subjects = []\n",
    "\n",
    "for texture_feature in texture_features:\n",
    "#     print(texture_feature)\n",
    "    \n",
    "    for key, value in pd.read_csv(texture_feature).iterrows():\n",
    "\n",
    "        subject = '_'.join(list(value)[0].split('_')[:-1])\n",
    "        label = label_dict[subject]\n",
    "        clinic_data = clinical_dict[subject] # is male, is female, age\n",
    "\n",
    "#         print(key, list(value)[0], len(list(value[1:])), label, clinic_data)\n",
    "        \n",
    "        whole_feature.append(list(value[1:]) + clinic_data)\n",
    "        whole_label.append(label)\n",
    "        whole_subjects.append(list(value)[0])\n",
    "\n",
    "#         break\n",
    "        \n",
    "print('Whole feature :',np.array(whole_feature).shape) # (270 = 135 + 135, 854 = 851 + 3)\n",
    "print('Whole labels :', np.array(whole_label).shape)\n",
    "print('Whole subjects :', len(whole_subjects))\n",
    "print('Number by labels :',Counter(whole_label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Analysis with Lasso\n",
    "\n",
    "- LASSO feature Extraction Method applied \n",
    "- Scaled data ( x - mean / std ) were used ( mean, std from train dataset were applied to test dataset )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++\n",
      "1 st try\n",
      "++++++++++\n",
      "\n",
      "1 Number of Feature Selected with  0.01 : 30\n",
      "30\n",
      "Ensemble Voting Grid search running...\n",
      "Random Forest Grid search running...\n",
      "{'class_weight': None, 'criterion': 'gini', 'max_depth': 8, 'max_features': 'auto', 'n_estimators': 200}\n",
      "XGBoost Grid search running...\n",
      "{'booster': 'gbtree', 'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 500}\n",
      "Adaboost Grid search running...\n",
      "{'learning_rate': 1.0, 'n_estimators': 200}\n",
      "Estimators Ready\n",
      "Voting Classifier Grid search running ... \n",
      "{'voting': 'soft'}\n",
      "done\n",
      "================================\n",
      "Test with  30  features\n",
      "================================\n",
      "Validation\n",
      "confusion :  [[17  1]\n",
      " [ 9  9]]\n",
      "Accuracy : 0.722\n",
      "roc-auc score : 0.917\n",
      "f1 score : 0.643\n",
      "precision : 0.900\n",
      "================================\n",
      "2 Number of Feature Selected with  0.02 : 25\n",
      "25\n",
      "Ensemble Voting Grid search running...\n",
      "Random Forest Grid search running...\n",
      "{'class_weight': None, 'criterion': 'gini', 'max_depth': 8, 'max_features': 'auto', 'n_estimators': 400}\n",
      "XGBoost Grid search running...\n",
      "{'booster': 'gbtree', 'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 500}\n",
      "Adaboost Grid search running...\n",
      "{'learning_rate': 1.0, 'n_estimators': 200}\n",
      "Estimators Ready\n",
      "Voting Classifier Grid search running ... \n",
      "{'voting': 'soft'}\n",
      "done\n",
      "================================\n",
      "Test with  25  features\n",
      "================================\n",
      "Validation\n",
      "confusion :  [[17  1]\n",
      " [ 9  9]]\n",
      "Accuracy : 0.722\n",
      "roc-auc score : 0.920\n",
      "f1 score : 0.643\n",
      "precision : 0.900\n",
      "================================\n",
      "3 Number of Feature Selected with  0.03 : 24\n",
      "24\n",
      "Ensemble Voting Grid search running...\n",
      "Random Forest Grid search running...\n",
      "{'class_weight': None, 'criterion': 'gini', 'max_depth': 8, 'max_features': 'auto', 'n_estimators': 200}\n",
      "XGBoost Grid search running...\n",
      "{'booster': 'gbtree', 'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 500}\n",
      "Adaboost Grid search running...\n",
      "{'learning_rate': 1.0, 'n_estimators': 200}\n",
      "Estimators Ready\n",
      "Voting Classifier Grid search running ... \n",
      "{'voting': 'soft'}\n",
      "done\n",
      "================================\n",
      "Test with  24  features\n",
      "================================\n",
      "Validation\n",
      "confusion :  [[17  1]\n",
      " [ 9  9]]\n",
      "Accuracy : 0.722\n",
      "roc-auc score : 0.926\n",
      "f1 score : 0.643\n",
      "precision : 0.900\n",
      "================================\n",
      "4 Number of Feature Selected with  0.04 : 20\n",
      "20\n",
      "Ensemble Voting Grid search running...\n",
      "Random Forest Grid search running...\n",
      "{'class_weight': None, 'criterion': 'gini', 'max_depth': 8, 'max_features': 'auto', 'n_estimators': 300}\n",
      "XGBoost Grid search running...\n",
      "{'booster': 'gbtree', 'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 200}\n",
      "Adaboost Grid search running...\n",
      "{'learning_rate': 0.1, 'n_estimators': 200}\n",
      "Estimators Ready\n",
      "Voting Classifier Grid search running ... \n",
      "{'voting': 'soft'}\n",
      "done\n",
      "================================\n",
      "Test with  20  features\n",
      "================================\n",
      "Validation\n",
      "confusion :  [[17  1]\n",
      " [ 7 11]]\n",
      "Accuracy : 0.778\n",
      "roc-auc score : 0.926\n",
      "f1 score : 0.733\n",
      "precision : 0.917\n",
      "================================\n",
      "5 Number of Feature Selected with  0.05 : 11\n",
      "11\n",
      "Ensemble Voting Grid search running...\n",
      "Random Forest Grid search running...\n",
      "{'class_weight': None, 'criterion': 'gini', 'max_depth': 8, 'max_features': 'auto', 'n_estimators': 200}\n",
      "XGBoost Grid search running...\n",
      "{'booster': 'gbtree', 'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 200}\n",
      "Adaboost Grid search running...\n",
      "{'learning_rate': 0.1, 'n_estimators': 300}\n",
      "Estimators Ready\n",
      "Voting Classifier Grid search running ... \n",
      "{'voting': 'soft'}\n",
      "done\n",
      "================================\n",
      "Test with  11  features\n",
      "================================\n",
      "Validation\n",
      "confusion :  [[16  2]\n",
      " [ 4 14]]\n",
      "Accuracy : 0.833\n",
      "roc-auc score : 0.917\n",
      "f1 score : 0.824\n",
      "precision : 0.875\n",
      "================================\n",
      "6 Number of Feature Selected with  0.06 : 10\n",
      "10\n",
      "Ensemble Voting Grid search running...\n",
      "Random Forest Grid search running...\n",
      "{'class_weight': None, 'criterion': 'gini', 'max_depth': 8, 'max_features': 'auto', 'n_estimators': 200}\n",
      "XGBoost Grid search running...\n",
      "{'booster': 'gbtree', 'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 500}\n",
      "Adaboost Grid search running...\n",
      "{'learning_rate': 0.1, 'n_estimators': 200}\n",
      "Estimators Ready\n",
      "Voting Classifier Grid search running ... \n",
      "{'voting': 'soft'}\n",
      "done\n",
      "================================\n",
      "Test with  10  features\n",
      "================================\n",
      "Validation\n",
      "confusion :  [[16  2]\n",
      " [ 6 12]]\n",
      "Accuracy : 0.778\n",
      "roc-auc score : 0.914\n",
      "f1 score : 0.750\n",
      "precision : 0.857\n",
      "================================\n",
      "7 Number of Feature Selected with  0.07 : 8\n",
      "8\n",
      "Ensemble Voting Grid search running...\n",
      "Random Forest Grid search running...\n",
      "{'class_weight': None, 'criterion': 'gini', 'max_depth': 8, 'max_features': 'auto', 'n_estimators': 200}\n",
      "XGBoost Grid search running...\n",
      "{'booster': 'gbtree', 'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 200}\n",
      "Adaboost Grid search running...\n",
      "{'learning_rate': 0.1, 'n_estimators': 200}\n",
      "Estimators Ready\n",
      "Voting Classifier Grid search running ... \n",
      "{'voting': 'soft'}\n",
      "done\n",
      "================================\n",
      "Test with  8  features\n",
      "================================\n",
      "Validation\n",
      "confusion :  [[17  1]\n",
      " [ 8 10]]\n",
      "Accuracy : 0.750\n",
      "roc-auc score : 0.910\n",
      "f1 score : 0.690\n",
      "precision : 0.909\n",
      "================================\n",
      "8 Number of Feature Selected with  0.08 : 5\n",
      "5\n",
      "Ensemble Voting Grid search running...\n",
      "Random Forest Grid search running...\n",
      "{'class_weight': None, 'criterion': 'gini', 'max_depth': 8, 'max_features': 'auto', 'n_estimators': 200}\n",
      "XGBoost Grid search running...\n",
      "{'booster': 'gbtree', 'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 200}\n",
      "Adaboost Grid search running...\n",
      "{'learning_rate': 0.1, 'n_estimators': 100}\n",
      "Estimators Ready\n",
      "Voting Classifier Grid search running ... \n",
      "{'voting': 'soft'}\n",
      "done\n",
      "================================\n",
      "Test with  5  features\n",
      "================================\n",
      "Validation\n",
      "confusion :  [[17  1]\n",
      " [ 5 13]]\n",
      "Accuracy : 0.833\n",
      "roc-auc score : 0.929\n",
      "f1 score : 0.813\n",
      "precision : 0.929\n",
      "================================\n",
      "++++++++++\n",
      "2 st try\n",
      "++++++++++\n",
      "\n",
      "1 Number of Feature Selected with  0.01 : 36\n",
      "36\n",
      "Ensemble Voting Grid search running...\n",
      "Random Forest Grid search running...\n",
      "{'class_weight': None, 'criterion': 'gini', 'max_depth': 8, 'max_features': 'auto', 'n_estimators': 400}\n",
      "XGBoost Grid search running...\n",
      "{'booster': 'gbtree', 'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 200}\n",
      "Adaboost Grid search running...\n",
      "{'learning_rate': 1.0, 'n_estimators': 200}\n",
      "Estimators Ready\n",
      "Voting Classifier Grid search running ... \n",
      "{'voting': 'soft'}\n",
      "done\n",
      "================================\n",
      "Test with  36  features\n",
      "================================\n",
      "Validation\n",
      "confusion :  [[13  5]\n",
      " [ 0 18]]\n",
      "Accuracy : 0.861\n",
      "roc-auc score : 0.923\n",
      "f1 score : 0.878\n",
      "precision : 0.783\n",
      "================================\n",
      "2 Number of Feature Selected with  0.02 : 31\n",
      "31\n",
      "Ensemble Voting Grid search running...\n",
      "Random Forest Grid search running...\n",
      "{'class_weight': None, 'criterion': 'gini', 'max_depth': 8, 'max_features': 'auto', 'n_estimators': 200}\n",
      "XGBoost Grid search running...\n",
      "{'booster': 'gbtree', 'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 200}\n",
      "Adaboost Grid search running...\n",
      "{'learning_rate': 1.0, 'n_estimators': 300}\n",
      "Estimators Ready\n",
      "Voting Classifier Grid search running ... \n",
      "{'voting': 'soft'}\n",
      "done\n",
      "================================\n",
      "Test with  31  features\n",
      "================================\n",
      "Validation\n",
      "confusion :  [[12  6]\n",
      " [ 0 18]]\n",
      "Accuracy : 0.833\n",
      "roc-auc score : 0.926\n",
      "f1 score : 0.857\n",
      "precision : 0.750\n",
      "================================\n",
      "3 Number of Feature Selected with  0.03 : 25\n",
      "25\n",
      "Ensemble Voting Grid search running...\n",
      "Random Forest Grid search running...\n",
      "{'class_weight': None, 'criterion': 'gini', 'max_depth': 8, 'max_features': 'auto', 'n_estimators': 300}\n",
      "XGBoost Grid search running...\n",
      "{'booster': 'gbtree', 'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 200}\n",
      "Adaboost Grid search running...\n",
      "{'learning_rate': 0.1, 'n_estimators': 200}\n",
      "Estimators Ready\n",
      "Voting Classifier Grid search running ... \n",
      "{'voting': 'soft'}\n",
      "done\n",
      "================================\n",
      "Test with  25  features\n",
      "================================\n",
      "Validation\n",
      "confusion :  [[15  3]\n",
      " [ 1 17]]\n",
      "Accuracy : 0.889\n",
      "roc-auc score : 0.920\n",
      "f1 score : 0.895\n",
      "precision : 0.850\n",
      "================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 Number of Feature Selected with  0.04 : 21\n",
      "21\n",
      "Ensemble Voting Grid search running...\n",
      "Random Forest Grid search running...\n",
      "{'class_weight': None, 'criterion': 'gini', 'max_depth': 8, 'max_features': 'auto', 'n_estimators': 500}\n",
      "XGBoost Grid search running...\n",
      "{'booster': 'gbtree', 'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 200}\n",
      "Adaboost Grid search running...\n",
      "{'learning_rate': 1.0, 'n_estimators': 100}\n",
      "Estimators Ready\n",
      "Voting Classifier Grid search running ... \n",
      "{'voting': 'soft'}\n",
      "done\n",
      "================================\n",
      "Test with  21  features\n",
      "================================\n",
      "Validation\n",
      "confusion :  [[15  3]\n",
      " [ 1 17]]\n",
      "Accuracy : 0.889\n",
      "roc-auc score : 0.926\n",
      "f1 score : 0.895\n",
      "precision : 0.850\n",
      "================================\n",
      "5 Number of Feature Selected with  0.05 : 15\n",
      "15\n",
      "Ensemble Voting Grid search running...\n",
      "Random Forest Grid search running...\n",
      "{'class_weight': None, 'criterion': 'gini', 'max_depth': 8, 'max_features': 'auto', 'n_estimators': 400}\n",
      "XGBoost Grid search running...\n",
      "{'booster': 'gbtree', 'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 500}\n",
      "Adaboost Grid search running...\n",
      "{'learning_rate': 1.0, 'n_estimators': 300}\n",
      "Estimators Ready\n",
      "Voting Classifier Grid search running ... \n",
      "{'voting': 'soft'}\n",
      "done\n",
      "================================\n",
      "Test with  15  features\n",
      "================================\n",
      "Validation\n",
      "confusion :  [[15  3]\n",
      " [ 0 18]]\n",
      "Accuracy : 0.917\n",
      "roc-auc score : 0.917\n",
      "f1 score : 0.923\n",
      "precision : 0.857\n",
      "================================\n",
      "6 Number of Feature Selected with  0.06 : 10\n",
      "10\n",
      "Ensemble Voting Grid search running...\n",
      "Random Forest Grid search running...\n",
      "{'class_weight': None, 'criterion': 'gini', 'max_depth': 8, 'max_features': 'auto', 'n_estimators': 300}\n",
      "XGBoost Grid search running...\n",
      "{'booster': 'gbtree', 'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 500}\n",
      "Adaboost Grid search running...\n",
      "{'learning_rate': 1.0, 'n_estimators': 200}\n",
      "Estimators Ready\n",
      "Voting Classifier Grid search running ... \n",
      "{'voting': 'soft'}\n",
      "done\n",
      "================================\n",
      "Test with  10  features\n",
      "================================\n",
      "Validation\n",
      "confusion :  [[16  2]\n",
      " [ 1 17]]\n",
      "Accuracy : 0.917\n",
      "roc-auc score : 0.932\n",
      "f1 score : 0.919\n",
      "precision : 0.895\n",
      "================================\n",
      "7 Number of Feature Selected with  0.07 : 8\n",
      "8\n",
      "Ensemble Voting Grid search running...\n",
      "Random Forest Grid search running...\n",
      "{'class_weight': None, 'criterion': 'gini', 'max_depth': 8, 'max_features': 'auto', 'n_estimators': 200}\n",
      "XGBoost Grid search running...\n",
      "{'booster': 'gbtree', 'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 500}\n",
      "Adaboost Grid search running...\n",
      "{'learning_rate': 1.0, 'n_estimators': 200}\n",
      "Estimators Ready\n",
      "Voting Classifier Grid search running ... \n",
      "{'voting': 'soft'}\n",
      "done\n",
      "================================\n",
      "Test with  8  features\n",
      "================================\n",
      "Validation\n",
      "confusion :  [[16  2]\n",
      " [ 0 18]]\n",
      "Accuracy : 0.944\n",
      "roc-auc score : 0.944\n",
      "f1 score : 0.947\n",
      "precision : 0.900\n",
      "================================\n",
      "8 Number of Feature Selected with  0.08 : 6\n",
      "6\n",
      "Ensemble Voting Grid search running...\n",
      "Random Forest Grid search running...\n",
      "{'class_weight': None, 'criterion': 'gini', 'max_depth': 8, 'max_features': 'auto', 'n_estimators': 200}\n",
      "XGBoost Grid search running...\n",
      "{'booster': 'gbtree', 'learning_rate': 0.01, 'max_depth': 7, 'n_estimators': 200}\n",
      "Adaboost Grid search running...\n",
      "{'learning_rate': 0.1, 'n_estimators': 300}\n",
      "Estimators Ready\n",
      "Voting Classifier Grid search running ... \n",
      "{'voting': 'soft'}\n",
      "done\n",
      "================================\n",
      "Test with  6  features\n",
      "================================\n",
      "Validation\n",
      "confusion :  [[13  5]\n",
      " [ 1 17]]\n",
      "Accuracy : 0.833\n",
      "roc-auc score : 0.914\n",
      "f1 score : 0.850\n",
      "precision : 0.773\n",
      "================================\n",
      "++++++++++\n",
      "3 st try\n",
      "++++++++++\n",
      "\n",
      "1 Number of Feature Selected with  0.01 : 27\n",
      "27\n",
      "Ensemble Voting Grid search running...\n",
      "Random Forest Grid search running...\n",
      "{'class_weight': None, 'criterion': 'gini', 'max_depth': 8, 'max_features': 'auto', 'n_estimators': 300}\n",
      "XGBoost Grid search running...\n",
      "{'booster': 'gbtree', 'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 200}\n",
      "Adaboost Grid search running...\n",
      "{'learning_rate': 1.0, 'n_estimators': 200}\n",
      "Estimators Ready\n",
      "Voting Classifier Grid search running ... \n",
      "{'voting': 'soft'}\n",
      "done\n",
      "================================\n",
      "Test with  27  features\n",
      "================================\n",
      "Validation\n",
      "confusion :  [[13  5]\n",
      " [ 2 16]]\n",
      "Accuracy : 0.806\n",
      "roc-auc score : 0.929\n",
      "f1 score : 0.821\n",
      "precision : 0.762\n",
      "================================\n",
      "2 Number of Feature Selected with  0.02 : 22\n",
      "22\n",
      "Ensemble Voting Grid search running...\n",
      "Random Forest Grid search running...\n",
      "{'class_weight': None, 'criterion': 'gini', 'max_depth': 8, 'max_features': 'auto', 'n_estimators': 200}\n",
      "XGBoost Grid search running...\n",
      "{'booster': 'gbtree', 'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 500}\n",
      "Adaboost Grid search running...\n",
      "{'learning_rate': 1.0, 'n_estimators': 200}\n",
      "Estimators Ready\n",
      "Voting Classifier Grid search running ... \n",
      "{'voting': 'soft'}\n",
      "done\n",
      "================================\n",
      "Test with  22  features\n",
      "================================\n",
      "Validation\n",
      "confusion :  [[12  6]\n",
      " [ 3 15]]\n",
      "Accuracy : 0.750\n",
      "roc-auc score : 0.929\n",
      "f1 score : 0.769\n",
      "precision : 0.714\n",
      "================================\n",
      "3 Number of Feature Selected with  0.03 : 17\n",
      "17\n",
      "Ensemble Voting Grid search running...\n",
      "Random Forest Grid search running...\n",
      "{'class_weight': None, 'criterion': 'gini', 'max_depth': 8, 'max_features': 'auto', 'n_estimators': 200}\n",
      "XGBoost Grid search running...\n",
      "{'booster': 'gbtree', 'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 500}\n",
      "Adaboost Grid search running...\n",
      "{'learning_rate': 1.0, 'n_estimators': 50}\n",
      "Estimators Ready\n",
      "Voting Classifier Grid search running ... \n",
      "{'voting': 'soft'}\n",
      "done\n",
      "================================\n",
      "Test with  17  features\n",
      "================================\n",
      "Validation\n",
      "confusion :  [[13  5]\n",
      " [ 3 15]]\n",
      "Accuracy : 0.778\n",
      "roc-auc score : 0.898\n",
      "f1 score : 0.789\n",
      "precision : 0.750\n",
      "================================\n",
      "4 Number of Feature Selected with  0.04 : 15\n",
      "15\n",
      "Ensemble Voting Grid search running...\n",
      "Random Forest Grid search running...\n",
      "{'class_weight': None, 'criterion': 'gini', 'max_depth': 8, 'max_features': 'auto', 'n_estimators': 300}\n",
      "XGBoost Grid search running...\n",
      "{'booster': 'gbtree', 'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 200}\n",
      "Adaboost Grid search running...\n",
      "{'learning_rate': 0.1, 'n_estimators': 100}\n",
      "Estimators Ready\n",
      "Voting Classifier Grid search running ... \n",
      "{'voting': 'soft'}\n",
      "done\n",
      "================================\n",
      "Test with  15  features\n",
      "================================\n",
      "Validation\n",
      "confusion :  [[14  4]\n",
      " [ 3 15]]\n",
      "Accuracy : 0.806\n",
      "roc-auc score : 0.932\n",
      "f1 score : 0.811\n",
      "precision : 0.789\n",
      "================================\n",
      "5 Number of Feature Selected with  0.05 : 13\n",
      "13\n",
      "Ensemble Voting Grid search running...\n",
      "Random Forest Grid search running...\n",
      "{'class_weight': None, 'criterion': 'gini', 'max_depth': 8, 'max_features': 'auto', 'n_estimators': 400}\n",
      "XGBoost Grid search running...\n",
      "{'booster': 'gbtree', 'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 200}\n",
      "Adaboost Grid search running...\n",
      "{'learning_rate': 0.1, 'n_estimators': 100}\n",
      "Estimators Ready\n",
      "Voting Classifier Grid search running ... \n",
      "{'voting': 'soft'}\n",
      "done\n",
      "================================\n",
      "Test with  13  features\n",
      "================================\n",
      "Validation\n",
      "confusion :  [[17  1]\n",
      " [ 5 13]]\n",
      "Accuracy : 0.833\n",
      "roc-auc score : 0.907\n",
      "f1 score : 0.813\n",
      "precision : 0.929\n",
      "================================\n",
      "6 Number of Feature Selected with  0.06 : 10\n",
      "10\n",
      "Ensemble Voting Grid search running...\n",
      "Random Forest Grid search running...\n",
      "{'class_weight': None, 'criterion': 'gini', 'max_depth': 8, 'max_features': 'auto', 'n_estimators': 200}\n",
      "XGBoost Grid search running...\n",
      "{'booster': 'gbtree', 'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 200}\n",
      "Adaboost Grid search running...\n",
      "{'learning_rate': 0.1, 'n_estimators': 200}\n",
      "Estimators Ready\n",
      "Voting Classifier Grid search running ... \n",
      "{'voting': 'soft'}\n",
      "done\n",
      "================================\n",
      "Test with  10  features\n",
      "================================\n",
      "Validation\n",
      "confusion :  [[13  5]\n",
      " [ 2 16]]\n",
      "Accuracy : 0.806\n",
      "roc-auc score : 0.904\n",
      "f1 score : 0.821\n",
      "precision : 0.762\n",
      "================================\n",
      "7 Number of Feature Selected with  0.07 : 8\n",
      "8\n",
      "Ensemble Voting Grid search running...\n",
      "Random Forest Grid search running...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'class_weight': None, 'criterion': 'gini', 'max_depth': 8, 'max_features': 'auto', 'n_estimators': 400}\n",
      "XGBoost Grid search running...\n",
      "{'booster': 'gbtree', 'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 200}\n",
      "Adaboost Grid search running...\n",
      "{'learning_rate': 1.0, 'n_estimators': 200}\n",
      "Estimators Ready\n",
      "Voting Classifier Grid search running ... \n",
      "{'voting': 'soft'}\n",
      "done\n",
      "================================\n",
      "Test with  8  features\n",
      "================================\n",
      "Validation\n",
      "confusion :  [[16  2]\n",
      " [ 4 14]]\n",
      "Accuracy : 0.833\n",
      "roc-auc score : 0.914\n",
      "f1 score : 0.824\n",
      "precision : 0.875\n",
      "================================\n",
      "8 Number of Feature Selected with  0.08 : 5\n",
      "5\n",
      "Ensemble Voting Grid search running...\n",
      "Random Forest Grid search running...\n",
      "{'class_weight': None, 'criterion': 'gini', 'max_depth': 8, 'max_features': 'auto', 'n_estimators': 400}\n",
      "XGBoost Grid search running...\n",
      "{'booster': 'gbtree', 'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 200}\n",
      "Adaboost Grid search running...\n",
      "{'learning_rate': 1.0, 'n_estimators': 200}\n",
      "Estimators Ready\n",
      "Voting Classifier Grid search running ... \n",
      "{'voting': 'soft'}\n",
      "done\n",
      "================================\n",
      "Test with  5  features\n",
      "================================\n",
      "Validation\n",
      "confusion :  [[15  3]\n",
      " [ 6 12]]\n",
      "Accuracy : 0.750\n",
      "roc-auc score : 0.907\n",
      "f1 score : 0.727\n",
      "precision : 0.800\n",
      "================================\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "num_try = 3\n",
    "try_dict = dict()\n",
    "\n",
    "# feature_data = feature_data_with_clinical\n",
    "highest_acc = 0.0\n",
    "binary = True\n",
    "\n",
    "classification_result_save_dir = '../classification_result/cn_ad/'\n",
    "target_names = ['CN', 'AD']\n",
    "delete_label = 1\n",
    "\n",
    "internal_feature_data = whole_feature\n",
    "internal_feature_label = np.array(whole_label)\n",
    "\n",
    "# if Bianary remove MCI\n",
    "if binary:\n",
    "    internal_feature_data, internal_feature_label = \\\n",
    "                        binary_class_configuration(internal_feature_data, internal_feature_label, delete_label)\n",
    "    \n",
    "    internal_feature_data = np.array(internal_feature_data)\n",
    "    \n",
    "    # 2 label ==> 1 label / 1 이 사라졌기 때문에..!\n",
    "    internal_feature_data[internal_feature_data == 2] = 1\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "trs = [0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08]\n",
    "#  first try : 23, 18, 13, 8, 8, 6, 4, 3\n",
    "\n",
    "# trs = [0.07] # 4\n",
    "\n",
    "for i in range(num_try):\n",
    "    \n",
    "    print(\"++++++++++\")\n",
    "    print(i+1 , \"st try\")\n",
    "    print(\"++++++++++\\n\")\n",
    "        \n",
    "    # train test set divide\n",
    "    X_train, X_test, y_train, y_test = train_test_split(internal_feature_data,\n",
    "                                                        internal_feature_label,\n",
    "                                                        test_size=0.20,\n",
    "                                                        random_state=42+i,\n",
    "                                                        stratify = internal_feature_label)\n",
    "    y_test = np.array(y_test)\n",
    "    y_test[y_test == 2] = 1\n",
    "        \n",
    "    X_train_resampled, Y_train_resampled = X_train, y_train\n",
    "\n",
    "    # Scale dataset\n",
    "    scaler.fit(X_train_resampled)\n",
    "    X_train_scaled = scaler.transform(X_train_resampled)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    for i, tr in enumerate(trs):\n",
    "\n",
    "        # Texture Feature Selection\n",
    "        sfm = Lasso_feature_selection(X_train_scaled[:, :-3], Y_train_resampled, tr=tr)\n",
    "        num_selected_feature = len(np.where(sfm.get_support() == True)[0])\n",
    "        print(i+1,'Number of Feature Selected with ', tr , ':', num_selected_feature)\n",
    "\n",
    "        X_train_new = np.hstack([sfm.transform(X_train_scaled[:, :-3]), X_train_scaled[:, -3:]])\n",
    "        X_test_tr = np.hstack([sfm.transform(X_test_scaled[:, :-3]), X_test_scaled[:, -3:]])\n",
    "\n",
    "        print(num_selected_feature)\n",
    "\n",
    "        clf = ensemble_voting(X_train_new, Y_train_resampled, random_state=42+i, cv=5)\n",
    "\n",
    "#         train\n",
    "        clf.fit(X_train_new, Y_train_resampled)\n",
    "\n",
    "        # evaluation\n",
    "\n",
    "        print('================================')\n",
    "        print(\"Test with \", num_selected_feature, \" features\")\n",
    "\n",
    "        internal_result = Validation(clf, X_test_tr, y_test)\n",
    "        \n",
    "        # multilabel 에 대한 confusion matrix 를 어떻게 구할까.. 3차원인가 ??\n",
    "#         confusion = internal_result[-1]; save_confusion_matrix(confusion, conf_index, conf_cols, \"Internal Validation Confusion matrix\")\n",
    "\n",
    "#         y_pred_proba = clf.predict_proba(X_test_tr); y_pred = clf.predict(X_test_tr)\n",
    "\n",
    "#         save_prediction(np.arange(len(y_pred)), y_pred, y_pred_proba, y_test,\\\n",
    "#                          os.path.join(classification_result_save_dir , str(num_selected_feature)+'.xlsx'),\n",
    "#                        binary=binary)\n",
    "        \n",
    "#         print(classification_report(y_test, y_pred, target_names = target_names))\n",
    "\n",
    "        print('================================')\n",
    "\n",
    "#             break\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({1: 74, 2: 72, 0: 70})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(Y_train_resampled)\n",
    "\n",
    "# - test set 을 balancing 하여 평가하였다\n",
    "#TODO 1: Confusion Matrix\n",
    "#TODO 2: AUROC score with multiple labels\n",
    "#TODO 3: "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
